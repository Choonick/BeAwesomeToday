## Daily Review 2016. 8. 11


1. 스칼라로 배우는 함수형 프로그래밍

	순수 함수적 병렬성
	
	동시성을 처리하는 방식: '논리적 스테드'를 주어진 문제에 필요한 만큼 얼마든지 생성할 수 있게 하고, 그것들을 실제 OS 스레드들에 대응시키는 것은 나중에 처리하는 방식.
	
	명시적 분기
	
	두 병렬 과제의 결과들이 결합되어야 함을 지정하는 수단이 필요한가.  
	특정 과제를 비동기적으로 수행할지 아닐지를 선택하는 수단이 필요한가.
	
	API의 정련, 대수
	
	코드에 관한 법칙과 증명이 중요한 이유
	
	함수형 프로그래밍에서는 공통의 기능성을 추출하고 합성을 통해 재사용 가능한 일반적 구성요소를 만들기 쉬우며, 그런 일이 당연시 됨.
	
	map에 관한 법칙, fork에 관한 법칙, actor, message, ...
	
	병렬 및 비동기 계산을 순수 함수적 방식으로!!
	
2. CS224d

	Lecture 4:  Word Window Classification and Neural Networks
	
	아직 어려운 것은 없음.
	
	Classification 문제에 대해서..
	
	조언
	
	- If you only have a small training data set, don’t train the word vectors.
	- If you have have a very large dataset, it may work better to train word vectors to the task.

	Word vectors = word embeddings = word representations (mostly)
	
	Window classification
	
	- Softmax의 과정을 다룸.
	- There are two expensive operations in the softmax
	- Softmax only gives linear decision boundaries in the original space.

	**From logistic regression to neural nets**

	A neural network= running several logistic regressions at the same time
	