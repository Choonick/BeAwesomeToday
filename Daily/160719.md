## Daily Review 2016. 7. 19


1. Neural Network for Machine Learning by hinton
	
	Lecture 1
	
	머신 러닝을 왜 배우는가.  
	머신러닝을 통해 할 수 있는 것들.  
	사람의 두뇌를 모방한 Neural Network.
	- Modularity and the brain
	
	Simple model
	
	- Linear neurons
	- Binary threshold neurons(1943)
	- ReLU(Rectified Linear Neurons) => non-linear
	- Sigmoid => smooth한 곡선이 그려져서 학습에 좋았음.
	- Stochastic binary neurons
	
	Type of learning task
	
	- Supervised Learning
	- Reinforcement Learning
	- Unsupercised Learning
		- create internal representation for supervised learning or reinforcement learning
	
2. 테스트 주도 개발

  리팩토링
  - 차이점 일치시키기
  - 변화 격리하기
  - 데이터 이주시키기
  - 메서드 추출하기
  - 메서드 인라인
  - 인터페이스 추출하가
  - 메서드 옮기기
  - 메서드 객체
  - 매개 변수 추가
  - 메서드 매개 변수를 생성사 매개 변수로 바꾸기

3. Adaboost

	 f(x) = 시그마 (t=1 ~ T) At Ht (x)

	 - h = 약분류기
	 - A = 가중치(신뢰도)
	 - T = 분류기의 개수
	 - f(x) = 강분류기

	 Process
	 
	 ```bash
	 t=1;
	   강분류기 f(x) = empty;
	   
	   while (1 to T) {
	     과정 1) 모든 약분류기에 대해, 모든 학습 샘픔들을 테스트.
	     과정 2) 최소 에러를 보였던 약분류기 ht 를 선택한다.
	     과정 3) 과정 1,2 에 근거하여 약분류기의 가중치 wt를 계산한다.
	     과정 4) 강 분류기를 다음과 같이 업그레이드 한다.
	           새로운 강분류기 = 이전 단계의 강분류기 + wt * ht
	           
	     과정 5) 모든 학습 샘플에 대해 강분류기의 정확도 테스트.
	     과정 6) t++
	 ```
	 
	In Adaboost,“shortcomings” are identified by high-weight data points. 
	
	**Advantages**
	
	- Very simple to implement 
	- Feature selection on very large sets of features 
	- Fairly good generalization
	
	**Disadvantages **
	
	- Suboptimal solution for α¯ 
	- Can overfit in presence of noise

4. Gradient Boosting

	Gradient Boosting = Gradient Descent + Boosting

	Gradient Boosting 

	-  Fit an additive model (ensemble)                   in a forward stage-wise manner. 
	-  In each stage, introduce a weak learner to compensate the shortcomings of existing weak learners.
	-  In Gradient Boosting,“shortcomings” are identified by gradients.
	- Recall that, in Adaboost,“shortcomings” are identified by high-weight data points.
	- Both high-weight data points and gradients tell us how to improve our model.


	Gradient Boosting for Different Problem
	Difficult: regression ===> classification ===> ranking

	자세한 정리는 OneNote에...

5. [모두를 위한 머신러닝과 딥러닝의 강의 - 시즌 2 - Deep NLP](https://hunkim.github.io/ml/)

	시즌 1을 듣지는 않았지만.. CS231n응 응용하시는 것 같아서 안 들어도 될 듯.
	
	Lec 0: 수업의 개요
	
	- Bot lab1-1: API.ai의 개념 
	- Bot lab1-2: API.ai 사용해보기

	ChatBot을 시작으로... NLP에 대해서 진도나갈 예정!  
	
	API.ai 의 개념이 유용할 듯
	
	- Intent
	- Parameter
	- Context(Global Varible)
	- Parameter Entity